{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import statistics as stat\n",
    "import scipy.stats as scStat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DEAP Dataset\n",
    "\n",
    "The dataset contains 40 experiments for each of the 32 participants. The labels array contain the valence, arousal, dominance and liking ratings for each participant for each of the 40 experiments. The data array contains 8064 physiological/EEG signal data from 40 different channels for each of the 40 experiments for each of the 32 participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "We divide the 8064 readings per channel, into 10 batches of approximately 807 readings each. For each batch we extract the mean, median, maximum, minimum, standard deviation, variance, range, skewness and kurtosis values for the 807 readings. Hence for each of the 10 batches of a single channel we extract 9 values mentioned above, we get 90 values as our processed dataset. We further add the net mean, median, maximum, minimum, standard deviation, variance, range, skewness and kurtosis values for the entire 8064 readings along with the experiment and participant number to our dataset, bringing it up to 101 values per channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, trial, participantNumber):\n",
    "    extData = []\n",
    "    for x in np.array_split(data, 10):\n",
    "        extData.extend(calc_features(x))\n",
    "    extData.extend(calc_features(data))\n",
    "    extData.append(participantNumber)\n",
    "    extData.append(participantNumber)\n",
    "    return extData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_features(array):\n",
    "    return [stat.mean(array),\n",
    "                stat.median(array),\n",
    "                stat.variance(array),\n",
    "                stat.stdev(array),\n",
    "                max(array),\n",
    "                min(array),\n",
    "                scStat.mode(array)[0][0],\n",
    "                scStat.kurtosis(array),\n",
    "                scStat.skew(array, axis=0, bias=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features from each channel are extracted and appended to a df so that it can be stored into a csv file and accessed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_file(fileName, participantNumber):\n",
    "    with open(fileName, 'rb') as f: content = pickle.load(f, encoding='latin1')\n",
    "    data = content['data']\n",
    "    labels = content['labels']\n",
    "    extracted_features = []\n",
    "    for index, trialData in enumerate(data):\n",
    "        for i, channelData in enumerate(trialData):\n",
    "            extracted_features.append(extract_features(channelData, index, participantNumber))\n",
    "    df = pd.DataFrame(extracted_features)\n",
    "    df['Valance Label'] = list(labels[:,0])*int(len(df)/len(labels))\n",
    "    df['Arousal Label'] = list(labels[:,1])*int(len(df)/len(labels))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from DEAP Dataset\n",
    "\n",
    "The data from DEAP Dataset .dat files are read one by one and the extracted features are appended into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = ['s01.dat', 's02.dat', 's03.dat']\n",
    "participants = [1, 2, 3]\n",
    "for f, participantNumber in zip(files, participants):\n",
    "    process_data_file(f, participantNumber).to_csv('ExtractedFeatures.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from extracted features\n",
    "\n",
    "If you're reading from the provided csv file, learning starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [str(i) for i in range(0,99)]\n",
    "columns.extend(['experiment No', 'participant No', 'Valance Label', 'Arousal Label'])\n",
    "df = pd.read_csv('ExtractedFeatures.csv', header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
