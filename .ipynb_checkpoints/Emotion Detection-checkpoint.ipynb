{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project tries to classify the data from EEG signals as high Valance or low Valance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import statistics as stat\n",
    "import scipy.stats as scStat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DEAP Dataset\n",
    "\n",
    "The dataset contains 40 experiments for each of the 32 participants. The labels array contain the valence, arousal, dominance and liking ratings for each participant for each of the 40 experiments. The data array contains 8064 physiological/EEG signal data from 40 different channels for each of the 40 experiments for each of the 32 participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "We divide the 8064 readings per channel, into 10 batches of approximately 807 readings each. For each batch we extract the mean, median, maximum, minimum, standard deviation, variance, range, skewness and kurtosis values for the 807 readings. Hence for each of the 10 batches of a single channel we extract 9 values mentioned above, we get 90 values as our processed dataset. We further add the net mean, median, maximum, minimum, standard deviation, variance, range, skewness and kurtosis values for the entire 8064 readings along with the experiment and participant number to our dataset, bringing it up to 101 values per channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, trial, participantNumber):\n",
    "    extData = []\n",
    "    for x in np.array_split(data, 10):\n",
    "        extData.extend(calc_features(x))\n",
    "    extData.extend(calc_features(data))\n",
    "    extData.append(participantNumber)\n",
    "    extData.append(participantNumber)\n",
    "    return extData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_features(array):\n",
    "    return [stat.mean(array),\n",
    "                stat.median(array),\n",
    "                stat.variance(array),\n",
    "                stat.stdev(array),\n",
    "                max(array),\n",
    "                min(array),\n",
    "                scStat.mode(array)[0][0],\n",
    "                scStat.kurtosis(array),\n",
    "                scStat.skew(array, axis=0, bias=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features from each channel are extracted and appended to a df so that it can be stored into a csv file and accessed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_file(fileName, participantNumber):\n",
    "    with open(fileName, 'rb') as f: content = pickle.load(f, encoding='latin1')\n",
    "    data = content['data']\n",
    "    labels = content['labels']\n",
    "    extracted_features = []\n",
    "    for index, trialData in enumerate(data):\n",
    "        for i, channelData in enumerate(trialData):\n",
    "            extracted_features.append(extract_features(channelData, index, participantNumber))\n",
    "    df = pd.DataFrame(extracted_features)\n",
    "    df['Valance Label'] = list(labels[:,0])*int(len(df)/len(labels))\n",
    "    df['Arousal Label'] = list(labels[:,1])*int(len(df)/len(labels))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from DEAP Dataset\n",
    "\n",
    "The data from DEAP Dataset .dat files are read one by one and the extracted features are appended into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = ['s05.dat']\n",
    "participants = [int(x.split('.')[0][-1]) for x in files]\n",
    "for f, participantNumber in zip(files, participants):\n",
    "    process_data_file(f, participantNumber).to_csv('ExtractedFeatures.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from extracted features\n",
    "\n",
    "If you're reading from the provided csv file, learning starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [str(i) for i in range(0,99)]\n",
    "columns.extend(['experiment No', 'participant No', 'Valance Label', 'Arousal Label'])\n",
    "df = pd.read_csv('ExtractedFeatures.csv', header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Valance Label'] = df['Valance Label'].apply(lambda x: 1 if x>5 else 0)\n",
    "df['Arousal Label'] = df['Arousal Label'].apply(lambda x: 1 if x>5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.difference(['Valance Label', 'Arousal Label'])].values\n",
    "\n",
    "y_valance = np.array([x for i, x in enumerate(df['Valance Label'].values) if i%1640 < 40])\n",
    "y_arousal = np.array([x for i, x in enumerate(df['Arousal Label'].values) if i%1640 < 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(int(X.shape[0]/40),40,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building basic CNN Model\n",
    "This model follows the setup recommended in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(100, (3,3), padding=\"valid\", activation='tanh', input_shape = (40, 101, 1)))\n",
    "    \n",
    "    model.add(Conv2D(100, (3, 3), activation='tanh' ))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='tanh'))\n",
    "    model.add(Dropout(0.50))\n",
    "    \n",
    "    model.add(Dense(2, activation='softplus'))\n",
    "    \n",
    "    sgd = SGD(lr = 0.00001, momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss ='categorical_crossentropy', optimizer = sgd,metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Building a model for tuning using hyperparameters\n",
    "The function sets hyperparameters for the following:\n",
    "    - No. of input layers into 1st Conv layer\n",
    "    - No. subsequent conv layers\n",
    "    - No. of units in these layers\n",
    "    - No. of Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hyperparameter_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(hp.Int(\"input_units\", min_value=50, max_value=250, step=10),\n",
    "                     (3,3), padding=\"valid\", activation='tanh', input_shape = (40, 101, 1)))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\",1, 8)):\n",
    "        model.add(Conv2D(hp.Int(f\"conv_{i}_units\", min_value=50, max_value=250, step=10),\n",
    "                         (3, 3), activation='tanh' ))\n",
    "    \n",
    "    #model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    #model.add(Dropout(0.50))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    for i in range(hp.Int(\"n_layers\",0, 4)):\n",
    "        model.add(Dense(hp.Int(f\"dense_{i}_units\", min_value=64, max_value=256, step=16), activation='tanh'))\n",
    "    \n",
    "    model.add(Dropout(0.50))\n",
    "    \n",
    "    model.add(Dense(2, activation='softplus'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]) \n",
    "    sgd = SGD(lr = hp_learning_rate, momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss ='categorical_crossentropy', optimizer = sgd,metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valance = to_categorical(y_valance, num_classes=2)\n",
    "y_arousal = to_categorical(y_arousal, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold cross validation before hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 12s - loss: 0.6987 - acc: 0.60 - ETA: 7s - loss: 0.7020 - acc: 0.6000 - ETA: 3s - loss: 0.7314 - acc: 0.580 - 16s 79ms/sample - loss: 0.8062 - acc: 0.5500 - val_loss: 0.7366 - val_acc: 0.4750\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.8024 - acc: 0.52 - ETA: 6s - loss: 0.8050 - acc: 0.5300 - ETA: 3s - loss: 0.7488 - acc: 0.580 - 15s 73ms/sample - loss: 0.7617 - acc: 0.5850 - val_loss: 0.7460 - val_acc: 0.4500\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 11s - loss: 0.7323 - acc: 0.56 - ETA: 7s - loss: 0.7530 - acc: 0.5200 - ETA: 3s - loss: 0.7469 - acc: 0.553 - 15s 76ms/sample - loss: 0.7909 - acc: 0.5250 - val_loss: 0.7501 - val_acc: 0.4750\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.9116 - acc: 0.48 - ETA: 6s - loss: 0.7699 - acc: 0.5700 - ETA: 3s - loss: 0.7798 - acc: 0.560 - 15s 73ms/sample - loss: 0.7696 - acc: 0.5550 - val_loss: 0.7489 - val_acc: 0.4750\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7307 - acc: 0.46 - ETA: 6s - loss: 0.7974 - acc: 0.4500 - ETA: 3s - loss: 0.8142 - acc: 0.466 - 15s 73ms/sample - loss: 0.7977 - acc: 0.4850 - val_loss: 0.7381 - val_acc: 0.4750\n",
      "40/40 [==============================] - ETA: 1s - loss: 0.5470 - acc: 1.000 - ETA: 1s - loss: 0.5704 - acc: 0.666 - ETA: 1s - loss: 0.6776 - acc: 0.600 - ETA: 1s - loss: 0.6233 - acc: 0.714 - ETA: 1s - loss: 0.6134 - acc: 0.666 - ETA: 1s - loss: 0.6598 - acc: 0.545 - ETA: 1s - loss: 0.6926 - acc: 0.461 - ETA: 0s - loss: 0.7242 - acc: 0.400 - ETA: 0s - loss: 0.7203 - acc: 0.411 - ETA: 0s - loss: 0.6992 - acc: 0.473 - ETA: 0s - loss: 0.6914 - acc: 0.500 - ETA: 0s - loss: 0.6781 - acc: 0.545 - ETA: 0s - loss: 0.6683 - acc: 0.583 - ETA: 0s - loss: 0.6664 - acc: 0.615 - ETA: 0s - loss: 0.6727 - acc: 0.607 - ETA: 0s - loss: 0.6938 - acc: 0.566 - ETA: 0s - loss: 0.7045 - acc: 0.548 - ETA: 0s - loss: 0.7174 - acc: 0.515 - ETA: 0s - loss: 0.7377 - acc: 0.485 - ETA: 0s - loss: 0.7381 - acc: 0.486 - ETA: 0s - loss: 0.7434 - acc: 0.461 - 2s 40ms/sample - loss: 0.7381 - acc: 0.4750\n",
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.8206 - acc: 0.46 - ETA: 6s - loss: 0.8133 - acc: 0.4500 - ETA: 3s - loss: 0.8123 - acc: 0.460 - 15s 73ms/sample - loss: 0.8185 - acc: 0.4600 - val_loss: 0.6803 - val_acc: 0.5250\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7863 - acc: 0.46 - ETA: 6s - loss: 0.7500 - acc: 0.5000 - ETA: 3s - loss: 0.7497 - acc: 0.520 - 14s 72ms/sample - loss: 0.7590 - acc: 0.5050 - val_loss: 0.6803 - val_acc: 0.5500\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7012 - acc: 0.54 - ETA: 6s - loss: 0.7711 - acc: 0.4600 - ETA: 3s - loss: 0.7624 - acc: 0.486 - 14s 72ms/sample - loss: 0.7684 - acc: 0.4850 - val_loss: 0.6805 - val_acc: 0.5250\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.6943 - acc: 0.54 - ETA: 6s - loss: 0.7022 - acc: 0.5300 - ETA: 3s - loss: 0.6934 - acc: 0.560 - 14s 72ms/sample - loss: 0.6984 - acc: 0.5550 - val_loss: 0.6810 - val_acc: 0.5500\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7544 - acc: 0.58 - ETA: 6s - loss: 0.7363 - acc: 0.5600 - ETA: 3s - loss: 0.7133 - acc: 0.560 - 14s 72ms/sample - loss: 0.7220 - acc: 0.5400 - val_loss: 0.6807 - val_acc: 0.5250\n",
      "40/40 [==============================] - ETA: 1s - loss: 0.5402 - acc: 1.000 - ETA: 1s - loss: 0.5530 - acc: 1.000 - ETA: 1s - loss: 0.5531 - acc: 1.000 - ETA: 1s - loss: 0.5915 - acc: 0.857 - ETA: 1s - loss: 0.5774 - acc: 0.888 - ETA: 1s - loss: 0.6020 - acc: 0.818 - ETA: 1s - loss: 0.6021 - acc: 0.846 - ETA: 0s - loss: 0.6023 - acc: 0.866 - ETA: 0s - loss: 0.6026 - acc: 0.882 - ETA: 0s - loss: 0.6114 - acc: 0.894 - ETA: 0s - loss: 0.6212 - acc: 0.857 - ETA: 0s - loss: 0.6382 - acc: 0.782 - ETA: 0s - loss: 0.6460 - acc: 0.720 - ETA: 0s - loss: 0.6492 - acc: 0.703 - ETA: 0s - loss: 0.6557 - acc: 0.655 - ETA: 0s - loss: 0.6608 - acc: 0.612 - ETA: 0s - loss: 0.6698 - acc: 0.575 - ETA: 0s - loss: 0.6779 - acc: 0.542 - ETA: 0s - loss: 0.6768 - acc: 0.540 - ETA: 0s - loss: 0.6845 - acc: 0.512 - 1s 37ms/sample - loss: 0.6807 - acc: 0.5250\n",
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.6945 - acc: 0.56 - ETA: 6s - loss: 0.7009 - acc: 0.5500 - ETA: 3s - loss: 0.7025 - acc: 0.540 - 15s 73ms/sample - loss: 0.7182 - acc: 0.5300 - val_loss: 0.6869 - val_acc: 0.5250\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.6676 - acc: 0.60 - ETA: 6s - loss: 0.6593 - acc: 0.5900 - ETA: 3s - loss: 0.6870 - acc: 0.580 - 15s 73ms/sample - loss: 0.6765 - acc: 0.6000 - val_loss: 0.6863 - val_acc: 0.5250\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7181 - acc: 0.46 - ETA: 6s - loss: 0.6992 - acc: 0.5400 - ETA: 3s - loss: 0.7150 - acc: 0.513 - 14s 72ms/sample - loss: 0.7122 - acc: 0.5150 - val_loss: 0.6873 - val_acc: 0.5250\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7989 - acc: 0.44 - ETA: 6s - loss: 0.7913 - acc: 0.4400 - ETA: 3s - loss: 0.7699 - acc: 0.473 - 14s 72ms/sample - loss: 0.7648 - acc: 0.4750 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7377 - acc: 0.54 - ETA: 6s - loss: 0.7929 - acc: 0.4100 - ETA: 3s - loss: 0.7678 - acc: 0.446 - 15s 74ms/sample - loss: 0.7412 - acc: 0.4700 - val_loss: 0.6865 - val_acc: 0.5500\n",
      "40/40 [==============================] - ETA: 1s - loss: 0.4692 - acc: 1.000 - ETA: 1s - loss: 0.4505 - acc: 1.000 - ETA: 1s - loss: 0.5404 - acc: 0.750 - ETA: 1s - loss: 0.5806 - acc: 0.833 - ETA: 1s - loss: 0.5538 - acc: 0.875 - ETA: 1s - loss: 0.5796 - acc: 0.800 - ETA: 1s - loss: 0.5826 - acc: 0.833 - ETA: 0s - loss: 0.5681 - acc: 0.857 - ETA: 0s - loss: 0.5669 - acc: 0.875 - ETA: 0s - loss: 0.5826 - acc: 0.833 - ETA: 0s - loss: 0.5765 - acc: 0.850 - ETA: 0s - loss: 0.5972 - acc: 0.772 - ETA: 0s - loss: 0.6192 - acc: 0.708 - ETA: 0s - loss: 0.6430 - acc: 0.653 - ETA: 0s - loss: 0.6331 - acc: 0.678 - ETA: 0s - loss: 0.6492 - acc: 0.633 - ETA: 0s - loss: 0.6543 - acc: 0.625 - ETA: 0s - loss: 0.6680 - acc: 0.588 - ETA: 0s - loss: 0.6713 - acc: 0.583 - ETA: 0s - loss: 0.6837 - acc: 0.552 - 2s 38ms/sample - loss: 0.6865 - acc: 0.5500\n",
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7272 - acc: 0.42 - ETA: 7s - loss: 0.7364 - acc: 0.4400 - ETA: 3s - loss: 0.7219 - acc: 0.493 - 15s 74ms/sample - loss: 0.7045 - acc: 0.5250 - val_loss: 0.7088 - val_acc: 0.4250\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.6564 - acc: 0.64 - ETA: 6s - loss: 0.6566 - acc: 0.6200 - ETA: 3s - loss: 0.6749 - acc: 0.600 - 15s 73ms/sample - loss: 0.6712 - acc: 0.6100 - val_loss: 0.7133 - val_acc: 0.4000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.6914 - acc: 0.62 - ETA: 7s - loss: 0.6893 - acc: 0.5900 - ETA: 3s - loss: 0.6918 - acc: 0.580 - 16s 80ms/sample - loss: 0.7201 - acc: 0.5350 - val_loss: 0.7207 - val_acc: 0.4000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 11s - loss: 0.6665 - acc: 0.50 - ETA: 7s - loss: 0.7338 - acc: 0.4800 - ETA: 3s - loss: 0.7090 - acc: 0.500 - 16s 78ms/sample - loss: 0.6989 - acc: 0.5250 - val_loss: 0.7245 - val_acc: 0.4000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.8078 - acc: 0.46 - ETA: 6s - loss: 0.7216 - acc: 0.5400 - ETA: 3s - loss: 0.7110 - acc: 0.533 - 15s 73ms/sample - loss: 0.7034 - acc: 0.5350 - val_loss: 0.7239 - val_acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 1s - loss: 0.5919 - acc: 1.000 - ETA: 1s - loss: 0.6749 - acc: 0.666 - ETA: 1s - loss: 0.6928 - acc: 0.600 - ETA: 1s - loss: 0.6961 - acc: 0.571 - ETA: 1s - loss: 0.6540 - acc: 0.666 - ETA: 1s - loss: 0.6534 - acc: 0.636 - ETA: 1s - loss: 0.6600 - acc: 0.615 - ETA: 0s - loss: 0.6398 - acc: 0.666 - ETA: 0s - loss: 0.6428 - acc: 0.647 - ETA: 0s - loss: 0.6441 - acc: 0.631 - ETA: 0s - loss: 0.6457 - acc: 0.619 - ETA: 0s - loss: 0.6672 - acc: 0.565 - ETA: 0s - loss: 0.6691 - acc: 0.560 - ETA: 0s - loss: 0.6569 - acc: 0.592 - ETA: 0s - loss: 0.6678 - acc: 0.551 - ETA: 0s - loss: 0.6806 - acc: 0.516 - ETA: 0s - loss: 0.6900 - acc: 0.484 - ETA: 0s - loss: 0.7008 - acc: 0.457 - ETA: 0s - loss: 0.7099 - acc: 0.432 - ETA: 0s - loss: 0.7183 - acc: 0.410 - 1s 37ms/sample - loss: 0.7239 - acc: 0.4000\n",
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7234 - acc: 0.50 - ETA: 6s - loss: 0.7307 - acc: 0.5000 - ETA: 3s - loss: 0.7380 - acc: 0.493 - 15s 73ms/sample - loss: 0.7193 - acc: 0.5050 - val_loss: 0.5943 - val_acc: 0.7500\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7066 - acc: 0.58 - ETA: 6s - loss: 0.7125 - acc: 0.5400 - ETA: 3s - loss: 0.7231 - acc: 0.506 - 15s 73ms/sample - loss: 0.7174 - acc: 0.5150 - val_loss: 0.6017 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7188 - acc: 0.46 - ETA: 6s - loss: 0.7201 - acc: 0.4800 - ETA: 3s - loss: 0.7167 - acc: 0.453 - 14s 72ms/sample - loss: 0.7154 - acc: 0.4800 - val_loss: 0.6116 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7241 - acc: 0.58 - ETA: 6s - loss: 0.7243 - acc: 0.5700 - ETA: 3s - loss: 0.7273 - acc: 0.546 - 15s 73ms/sample - loss: 0.7223 - acc: 0.5350 - val_loss: 0.6225 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7533 - acc: 0.42 - ETA: 7s - loss: 0.7611 - acc: 0.4700 - ETA: 3s - loss: 0.7391 - acc: 0.486 - 15s 74ms/sample - loss: 0.7345 - acc: 0.4900 - val_loss: 0.6270 - val_acc: 0.7500\n",
      "40/40 [==============================] - ETA: 1s - loss: 0.5394 - acc: 1.000 - ETA: 1s - loss: 0.5585 - acc: 1.000 - ETA: 1s - loss: 0.5417 - acc: 1.000 - ETA: 1s - loss: 0.5561 - acc: 1.000 - ETA: 1s - loss: 0.5549 - acc: 1.000 - ETA: 1s - loss: 0.5546 - acc: 1.000 - ETA: 1s - loss: 0.5631 - acc: 0.916 - ETA: 0s - loss: 0.5697 - acc: 0.928 - ETA: 0s - loss: 0.5642 - acc: 0.937 - ETA: 0s - loss: 0.5583 - acc: 0.944 - ETA: 0s - loss: 0.5601 - acc: 0.950 - ETA: 0s - loss: 0.5612 - acc: 0.954 - ETA: 0s - loss: 0.5853 - acc: 0.875 - ETA: 0s - loss: 0.5816 - acc: 0.884 - ETA: 0s - loss: 0.5780 - acc: 0.892 - ETA: 0s - loss: 0.5869 - acc: 0.866 - ETA: 0s - loss: 0.5933 - acc: 0.843 - ETA: 0s - loss: 0.6055 - acc: 0.823 - ETA: 0s - loss: 0.6091 - acc: 0.805 - ETA: 0s - loss: 0.6233 - acc: 0.763 - 1s 36ms/sample - loss: 0.6270 - acc: 0.7500\n",
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7033 - acc: 0.46 - ETA: 6s - loss: 0.6966 - acc: 0.4600 - ETA: 3s - loss: 0.7020 - acc: 0.466 - 15s 73ms/sample - loss: 0.6963 - acc: 0.4900 - val_loss: 0.6656 - val_acc: 0.6750\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7354 - acc: 0.50 - ETA: 6s - loss: 0.7269 - acc: 0.5300 - ETA: 3s - loss: 0.7082 - acc: 0.526 - 15s 73ms/sample - loss: 0.7097 - acc: 0.5100 - val_loss: 0.6636 - val_acc: 0.6000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7450 - acc: 0.44 - ETA: 6s - loss: 0.6950 - acc: 0.5500 - ETA: 3s - loss: 0.7006 - acc: 0.566 - 15s 74ms/sample - loss: 0.6954 - acc: 0.5750 - val_loss: 0.6620 - val_acc: 0.6000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.7122 - acc: 0.56 - ETA: 6s - loss: 0.7074 - acc: 0.5400 - ETA: 3s - loss: 0.6982 - acc: 0.546 - 15s 74ms/sample - loss: 0.6842 - acc: 0.5800 - val_loss: 0.6622 - val_acc: 0.6000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 10s - loss: 0.6879 - acc: 0.56 - ETA: 6s - loss: 0.6865 - acc: 0.5800 - ETA: 3s - loss: 0.6969 - acc: 0.553 - 15s 73ms/sample - loss: 0.6988 - acc: 0.5400 - val_loss: 0.6611 - val_acc: 0.6000\n",
      "40/40 [==============================] - ETA: 1s - loss: 0.6088 - acc: 1.000 - ETA: 1s - loss: 0.6858 - acc: 0.666 - ETA: 1s - loss: 0.6946 - acc: 0.600 - ETA: 1s - loss: 0.6672 - acc: 0.714 - ETA: 1s - loss: 0.6477 - acc: 0.777 - ETA: 1s - loss: 0.6559 - acc: 0.727 - ETA: 0s - loss: 0.6630 - acc: 0.692 - ETA: 0s - loss: 0.6576 - acc: 0.733 - ETA: 0s - loss: 0.6500 - acc: 0.764 - ETA: 0s - loss: 0.6386 - acc: 0.789 - ETA: 0s - loss: 0.6453 - acc: 0.761 - ETA: 0s - loss: 0.6497 - acc: 0.739 - ETA: 0s - loss: 0.6528 - acc: 0.720 - ETA: 0s - loss: 0.6453 - acc: 0.740 - ETA: 0s - loss: 0.6513 - acc: 0.689 - ETA: 0s - loss: 0.6504 - acc: 0.677 - ETA: 0s - loss: 0.6514 - acc: 0.666 - ETA: 0s - loss: 0.6548 - acc: 0.657 - ETA: 0s - loss: 0.6593 - acc: 0.621 - ETA: 0s - loss: 0.6641 - acc: 0.589 - 1s 36ms/sample - loss: 0.6611 - acc: 0.6000\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "kf = KFold(n_splits=int(len(X)/40), shuffle=False)\n",
    "losses = []\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_valance[train_index], y_valance[test_index]\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], 40, 101, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 40, 101, 1)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size = 50, \n",
    "                        epochs = 5, validation_data = (X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, batch_size = 1)\n",
    "    losses.append(score[0])\n",
    "    accuracies.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.475, 0.525, 0.55, 0.4, 0.75, 0.6]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning using Keras-Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "180/180 [==============================] - ETA: 26s - loss: 0.8002 - acc: 0.40 - ETA: 16s - loss: 0.8942 - acc: 0.47 - ETA: 5s - loss: 0.8395 - acc: 0.5000 - 41s 226ms/sample - loss: 0.8240 - acc: 0.5111 - val_loss: 0.7862 - val_acc: 0.4500\n",
      "Epoch 2/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6938 - acc: 0.64 - ETA: 15s - loss: 0.6973 - acc: 0.62 - ETA: 5s - loss: 0.6805 - acc: 0.5933 - 39s 217ms/sample - loss: 0.6794 - acc: 0.5889 - val_loss: 0.7248 - val_acc: 0.4500\n",
      "Epoch 3/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6398 - acc: 0.68 - ETA: 15s - loss: 0.6776 - acc: 0.62 - ETA: 5s - loss: 0.6766 - acc: 0.5933 - 39s 218ms/sample - loss: 0.6635 - acc: 0.6111 - val_loss: 0.7313 - val_acc: 0.4500\n",
      "Epoch 4/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6087 - acc: 0.66 - ETA: 15s - loss: 0.6293 - acc: 0.64 - ETA: 5s - loss: 0.6286 - acc: 0.6467 - 39s 216ms/sample - loss: 0.6573 - acc: 0.6056 - val_loss: 0.7399 - val_acc: 0.4500\n",
      "Epoch 5/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6495 - acc: 0.58 - ETA: 15s - loss: 0.6648 - acc: 0.58 - ETA: 5s - loss: 0.6423 - acc: 0.6400 - 40s 223ms/sample - loss: 0.6483 - acc: 0.6278 - val_loss: 0.7648 - val_acc: 0.4667\n",
      "Train on 180 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "180/180 [==============================] - ETA: 26s - loss: 0.8087 - acc: 0.42 - ETA: 16s - loss: 0.7329 - acc: 0.55 - ETA: 6s - loss: 0.7628 - acc: 0.5467 - 41s 229ms/sample - loss: 0.7482 - acc: 0.5611 - val_loss: 0.7061 - val_acc: 0.5333\n",
      "Epoch 2/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6724 - acc: 0.54 - ETA: 15s - loss: 0.6599 - acc: 0.55 - ETA: 5s - loss: 0.6320 - acc: 0.6067 - 40s 222ms/sample - loss: 0.6381 - acc: 0.6222 - val_loss: 0.7893 - val_acc: 0.4500\n",
      "Epoch 3/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6954 - acc: 0.56 - ETA: 15s - loss: 0.6630 - acc: 0.62 - ETA: 5s - loss: 0.6967 - acc: 0.6133 - 39s 219ms/sample - loss: 0.7101 - acc: 0.5944 - val_loss: 0.7970 - val_acc: 0.4500\n",
      "Epoch 4/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6887 - acc: 0.50 - ETA: 16s - loss: 0.6147 - acc: 0.61 - ETA: 6s - loss: 0.6333 - acc: 0.5933 - 40s 221ms/sample - loss: 0.6373 - acc: 0.6111 - val_loss: 0.7499 - val_acc: 0.4500\n",
      "Epoch 5/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6198 - acc: 0.70 - ETA: 15s - loss: 0.6372 - acc: 0.63 - ETA: 5s - loss: 0.6198 - acc: 0.6733 - 40s 220ms/sample - loss: 0.6405 - acc: 0.6500 - val_loss: 0.7449 - val_acc: 0.5000\n",
      "Train on 180 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "180/180 [==============================] - ETA: 27s - loss: 0.6996 - acc: 0.50 - ETA: 17s - loss: 0.7072 - acc: 0.50 - ETA: 6s - loss: 0.6933 - acc: 0.5400 - 41s 229ms/sample - loss: 0.6883 - acc: 0.5611 - val_loss: 0.7820 - val_acc: 0.4500\n",
      "Epoch 2/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6268 - acc: 0.62 - ETA: 15s - loss: 0.6404 - acc: 0.62 - ETA: 5s - loss: 0.6904 - acc: 0.5533 - 39s 217ms/sample - loss: 0.6993 - acc: 0.5444 - val_loss: 0.7392 - val_acc: 0.4667\n",
      "Epoch 3/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6381 - acc: 0.66 - ETA: 15s - loss: 0.6359 - acc: 0.65 - ETA: 5s - loss: 0.6528 - acc: 0.6133 - 39s 217ms/sample - loss: 0.6542 - acc: 0.6278 - val_loss: 0.7568 - val_acc: 0.4667\n",
      "Epoch 4/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6703 - acc: 0.54 - ETA: 15s - loss: 0.6798 - acc: 0.56 - ETA: 5s - loss: 0.6648 - acc: 0.5733 - 39s 218ms/sample - loss: 0.6668 - acc: 0.5778 - val_loss: 0.7388 - val_acc: 0.4667\n",
      "Epoch 5/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6149 - acc: 0.70 - ETA: 15s - loss: 0.6217 - acc: 0.67 - ETA: 5s - loss: 0.6257 - acc: 0.6533 - 39s 219ms/sample - loss: 0.6350 - acc: 0.6389 - val_loss: 0.7440 - val_acc: 0.4667\n",
      "Train on 180 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "180/180 [==============================] - ETA: 28s - loss: 0.7190 - acc: 0.40 - ETA: 16s - loss: 0.6977 - acc: 0.50 - ETA: 6s - loss: 0.7040 - acc: 0.5333 - 41s 227ms/sample - loss: 0.7188 - acc: 0.5278 - val_loss: 0.7340 - val_acc: 0.4500\n",
      "Epoch 2/5\n",
      "180/180 [==============================] - ETA: 26s - loss: 0.6768 - acc: 0.64 - ETA: 16s - loss: 0.7346 - acc: 0.55 - ETA: 6s - loss: 0.7069 - acc: 0.5600 - 40s 222ms/sample - loss: 0.7202 - acc: 0.5556 - val_loss: 0.7241 - val_acc: 0.4500\n",
      "Epoch 3/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.7504 - acc: 0.52 - ETA: 15s - loss: 0.7175 - acc: 0.55 - ETA: 5s - loss: 0.6911 - acc: 0.5867 - 39s 217ms/sample - loss: 0.6765 - acc: 0.6111 - val_loss: 0.7261 - val_acc: 0.4500\n",
      "Epoch 4/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6772 - acc: 0.58 - ETA: 15s - loss: 0.6552 - acc: 0.62 - ETA: 5s - loss: 0.6411 - acc: 0.6467 - 39s 217ms/sample - loss: 0.6404 - acc: 0.6444 - val_loss: 0.7351 - val_acc: 0.4667\n",
      "Epoch 5/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.7423 - acc: 0.48 - ETA: 15s - loss: 0.6794 - acc: 0.57 - ETA: 5s - loss: 0.6841 - acc: 0.5867 - 39s 218ms/sample - loss: 0.6717 - acc: 0.6000 - val_loss: 0.7496 - val_acc: 0.4333\n",
      "Train on 180 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "180/180 [==============================] - ETA: 27s - loss: 0.7752 - acc: 0.54 - ETA: 16s - loss: 0.7367 - acc: 0.56 - ETA: 6s - loss: 0.7241 - acc: 0.5400 - 41s 227ms/sample - loss: 0.7468 - acc: 0.5056 - val_loss: 0.7084 - val_acc: 0.5333\n",
      "Epoch 2/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.7196 - acc: 0.54 - ETA: 15s - loss: 0.6874 - acc: 0.58 - ETA: 5s - loss: 0.6697 - acc: 0.6267 - 39s 216ms/sample - loss: 0.6802 - acc: 0.6111 - val_loss: 0.7514 - val_acc: 0.4667\n",
      "Epoch 3/5\n",
      "180/180 [==============================] - ETA: 26s - loss: 0.6468 - acc: 0.62 - ETA: 16s - loss: 0.6622 - acc: 0.61 - ETA: 5s - loss: 0.6796 - acc: 0.5867 - 39s 219ms/sample - loss: 0.6847 - acc: 0.5889 - val_loss: 0.7525 - val_acc: 0.4667\n",
      "Epoch 4/5\n",
      "180/180 [==============================] - ETA: 25s - loss: 0.6559 - acc: 0.64 - ETA: 15s - loss: 0.6408 - acc: 0.62 - ETA: 5s - loss: 0.6469 - acc: 0.6067 - 39s 218ms/sample - loss: 0.6459 - acc: 0.6222 - val_loss: 0.7783 - val_acc: 0.4667\n",
      "Epoch 5/5\n",
      "180/180 [==============================] - ETA: 26s - loss: 0.6576 - acc: 0.58 - ETA: 16s - loss: 0.6299 - acc: 0.62 - ETA: 6s - loss: 0.6367 - acc: 0.6267 - 43s 237ms/sample - loss: 0.6435 - acc: 0.6222 - val_loss: 0.7873 - val_acc: 0.4833\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a1592c30f43d88e0e07bdcf2744a52f4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.4933333396911621</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv_0_units: 140</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv_1_units: 50</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv_2_units: 50</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv_3_units: 50</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv_4_units: 50</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv_5_units: 50</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv_6_units: 50</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_0_units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_1_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_3_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_4_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_5_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_6_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 170</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_valance, random_state=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 40, 101, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 40, 101, 1)\n",
    "\n",
    "LOG_DIR = f'{int(time.time())}'\n",
    "\n",
    "tuner = RandomSearch(build_hyperparameter_model, \n",
    "                    objective='val_acc',\n",
    "                    max_trials=1,\n",
    "                    executions_per_trial = 5,\n",
    "                    directory=LOG_DIR)\n",
    "\n",
    "tuner.search(x=X_train,\n",
    "            y=y_train,\n",
    "            epochs=5,\n",
    "            batch_size=50,\n",
    "            validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kerastuner.engine.hyperparameters.HyperParameters at 0x184a02f4448>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
