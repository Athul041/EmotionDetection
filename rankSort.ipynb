{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Julia_Colab_Notebook_Template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> _Colab Notebook Template_\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). This takes a couple of minutes.\n",
        "4. Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeFXS0F0zww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c752ab-6e90-400a-b987-e0cf25bed717"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.7.1\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools Plots\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -n \"$COLAB_GPU\" ] && [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  if [ \"$COLAB_GPU\" = \"1\" ]; then\n",
        "      JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Julia 1.7.1 on the current Colab Runtime...\n",
            "2022-01-09 01:57:30 URL:https://storage.googleapis.com/julialang2/bin/linux/x64/1.7/julia-1.7.1-linux-x86_64.tar.gz [123374573/123374573] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "Installing Julia package BenchmarkTools...\n",
            "Installing Julia package Plots...\n",
            "Installing Julia package CUDA...\n",
            "Installing IJulia kernel...\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mInstalling julia kernelspec in /root/.local/share/jupyter/kernels/julia-1.7\n",
            "\n",
            "Successfully installed julia version 1.7.1!\n",
            "Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\n",
            "jump to the 'Checking the Installation' section.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OS3Ac017T1i"
      },
      "source": [
        "# Checking the Installation\n",
        "The `versioninfo()` function should print your Julia version and some other info about the system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzvvzCl1i0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e813df-5326-4939-f691-d7dcca56c88a"
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julia Version 1.7.1\n",
            "Commit ac5cc99908 (2021-12-22 19:35 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-pc-linux-gnu)\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-12.0.1 (ORCJIT, broadwell)\n",
            "Environment:\n",
            "  JULIA_NUM_THREADS = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using BenchmarkTools\n",
        "\n",
        "M = rand(2^11, 2^11)\n",
        "\n",
        "@btime $M * $M;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjM_qq54lCcs",
        "outputId": "3c1f27f7-42da-498b-d881-04983e69a13f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  464.119 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XciCcMAJOT3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80191b83-7d5b-4883-faec-7c56c2e1563d"
      },
      "source": [
        "if ENV[\"COLAB_GPU\"] == \"1\"\n",
        "    using CUDA\n",
        "\n",
        "    run(`nvidia-smi`)\n",
        "\n",
        "    # Create a new random matrix directly on the GPU:\n",
        "    M_on_gpu = CUDA.CURAND.rand(2^11, 2^11)\n",
        "    @btime $M_on_gpu * $M_on_gpu; nothing\n",
        "else\n",
        "    println(\"No GPU found.\")\n",
        "end"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 25 05:25:52 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "  464.167 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "const MAX_THREADS_PER_BLOCK = CUDA.attribute(CUDA.CuDevice(0), CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK,)"
      ],
      "metadata": {
        "id": "BMiWWCOHddly",
        "outputId": "a8898feb-bd58-4f56-b6a8-4efc4a824a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function rankSort(a::Vector{T}) where T\n",
        "    n = length(a)\n",
        "    println(a)\n",
        "    F_d = CuArray{T, 1}(a)\n",
        "    nThreads = MAX_THREADS_PER_BLOCK\n",
        "end"
      ],
      "metadata": {
        "id": "pjmC81DiWIAu",
        "outputId": "b018f5d7-7207-47ee-fab7-d2b4f1ca18e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rankSort (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = rand(10)\n",
        "rankSort(a)"
      ],
      "metadata": {
        "id": "x-nW5hEIWVE5",
        "outputId": "843b9162-1502-4ba4-f130-7ad24666c8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9508598417097023, 0.08537603753472178, 0.2569862360868822, 0.5536772450921306, 0.0783648435148383, 0.16727763086756386, 0.6165517368015515, 0.4406587706454097, 0.9157085153563967, 0.6192009262573246]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Error: @cuprint does not support values of type CuArray{Float64, 1, CUDA.Mem.DeviceBuffer}\n",
            "└ @ CUDA /root/.julia/packages/CUDA/KnJGx/src/device/intrinsics/output.jl:168\n",
            "\u001b[32m\u001b[1m Downloading\u001b[22m\u001b[39m artifact: CUDA_compat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LoadError",
          "evalue": "ignored",
          "traceback": [
            "CUDA error: unknown error (code 999, ERROR_UNKNOWN)",
            "",
            "Stacktrace:",
            "  [1] throw_api_error(res::CUDA.cudaError_enum)",
            "    @ CUDA ~/.julia/packages/CUDA/KnJGx/lib/cudadrv/error.jl:91",
            "  [2] macro expansion",
            "    @ ~/.julia/packages/CUDA/KnJGx/lib/cudadrv/error.jl:101 [inlined]",
            "  [3] cuDevicePrimaryCtxRetain",
            "    @ ~/.julia/packages/CUDA/KnJGx/lib/utils/call.jl:26 [inlined]",
            "  [4] CuContext",
            "    @ ~/.julia/packages/CUDA/KnJGx/lib/cudadrv/context.jl:57 [inlined]",
            "  [5] context(dev::CuDevice)",
            "    @ CUDA ~/.julia/packages/CUDA/KnJGx/lib/cudadrv/state.jl:222",
            "  [6] TaskLocalState (repeats 2 times)",
            "    @ ~/.julia/packages/CUDA/KnJGx/lib/cudadrv/state.jl:50 [inlined]",
            "  [7] task_local_state!()",
            "    @ CUDA ~/.julia/packages/CUDA/KnJGx/lib/cudadrv/state.jl:73",
            "  [8] active_state",
            "    @ ~/.julia/packages/CUDA/KnJGx/lib/cudadrv/state.jl:106 [inlined]",
            "  [9] #_alloc#198",
            "    @ ~/.julia/packages/CUDA/KnJGx/src/pool.jl:250 [inlined]",
            " [10] #alloc#197",
            "    @ ~/.julia/packages/CUDA/KnJGx/src/pool.jl:240 [inlined]",
            " [11] alloc",
            "    @ ~/.julia/packages/CUDA/KnJGx/src/pool.jl:236 [inlined]",
            " [12] CuArray",
            "    @ ~/.julia/packages/CUDA/KnJGx/src/array.jl:42 [inlined]",
            " [13] CuArray",
            "    @ ~/.julia/packages/CUDA/KnJGx/src/array.jl:287 [inlined]",
            " [14] CuArray",
            "    @ ~/.julia/packages/CUDA/KnJGx/src/array.jl:292 [inlined]",
            " [15] rankSort(a::Vector{Float64})",
            "    @ Main ./In[11]:4",
            " [16] top-level scope",
            "    @ In[12]:2",
            " [17] eval",
            "    @ ./boot.jl:373 [inlined]",
            " [18] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
            "    @ Base ./loading.jl:1196"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RC1QNNqk6h1"
      },
      "source": [
        "# Need Help?\n",
        "\n",
        "* Learning: https://julialang.org/learning/\n",
        "* Documentation: https://docs.julialang.org/\n",
        "* Questions & Discussions:\n",
        "  * https://discourse.julialang.org/\n",
        "  * http://julialang.slack.com/\n",
        "  * https://stackoverflow.com/questions/tagged/julia\n",
        "\n",
        "If you ever ask for help or file an issue about Julia, you should generally provide the output of `versioninfo()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UMidUQB03vJ"
      },
      "source": [
        "Add new code cells by clicking the `+ Code` button (or _Insert_ > _Code cell_).\n",
        "\n",
        "Have fun!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/JuliaLang/julia-logo-graphics/master/images/julia-logo-mask.png\" height=\"100\" />"
      ]
    }
  ]
}